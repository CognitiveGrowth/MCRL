{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import random\n",
    "import itertools as it\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from toolz import memoize\n",
    "from contracts import contract\n",
    "from collections import namedtuple, defaultdict, deque, Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "                        message=\"The objective has been evaluated at this point before.\")\n",
    "\n",
    "from agents import Agent\n",
    "from oldmouselab import OldMouselabEnv\n",
    "from policies import FixedPlanPolicy, LiederPolicy\n",
    "from evaluation import *\n",
    "from omdc_util import *\n",
    "from distributions import cmax, smax, sample, expectation, Normal, PointMass, SampleDist, Normal, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hd_dist(attributes):\n",
    "    dist = [1,]*attributes\n",
    "    dist[0] = np.random.randint(85,97)\n",
    "    for i in range(1,attributes-1):\n",
    "        dist[i] += np.random.randint(0,100-np.sum(dist))\n",
    "    dist[-1] += 100-np.sum(dist)\n",
    "    dist = np.around(np.array(dist)/100,decimals=2)\n",
    "    np.random.shuffle(dist)\n",
    "    return dist\n",
    "\n",
    "def ld_dist(attributes):\n",
    "    constrain = True\n",
    "    while constrain:\n",
    "        dist = [np.random.randint(10,50) for _ in range(attributes)]\n",
    "        dist = np.around(np.array(dist)/sum(dist),decimals=2)\n",
    "        constrain = np.min(dist) <= 0.10 or np.max(dist) >= 0.40\n",
    "    np.random.shuffle(dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gambles = 7\n",
    "attributes = 4\n",
    "high_stakes = Normal((9.99+0.01)/2, 0.3*(9.99-0.01))\n",
    "low_stakes = Normal((0.25+0.01)/2, 0.3*(0.25-0.01))\n",
    "reward = high_stakes\n",
    "cost=.03\n",
    "\n",
    "#set to 20 for sanity check\n",
    "n_train = 20\n",
    "n_test = 20\n",
    "\n",
    "train_envs_hd = [OldMouselabEnv(gambles, hd_dist(attributes), reward, cost) for _ in range(n_train)]\n",
    "train_envs_ld = [OldMouselabEnv(gambles, ld_dist(attributes), reward, cost) for _ in range(n_train)]\n",
    "train_envs = train_envs_hd+train_envs_ld \n",
    "\n",
    "test_envs_hd =  [OldMouselabEnv(gambles, hd_dist(attributes), reward, cost) for _ in range(n_train)]\n",
    "test_envs_ld = [OldMouselabEnv(gambles, ld_dist(attributes), reward, cost) for _ in range(n_train)]\n",
    "test_envs = test_envs_hd+test_envs_ld \n",
    "\n",
    "term_action = train_envs[0].term_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_pol_theta = np.load('data/om_bmps_pols/best/hs_hd_1cents.npy')\n",
    "bo_pol = LiederPolicy(list(bo_pol_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "def run_env(policy, env):\n",
    "    agent.register(env)\n",
    "    agent.register(policy)\n",
    "    tr = agent.run_episode()\n",
    "#     print(tr)\n",
    "    return {'util': tr['return'], 'actions': tr['actions'],\n",
    "            'observations': len(tr['actions']) - 1, 'ground_truth': env.ground_truth}\n",
    "\n",
    "def action_coordinate(env, action):\n",
    "    return (action//env.outcomes,action%env.outcomes)\n",
    "\n",
    "def p_grid(env, actions):\n",
    "    grid = np.zeros((env.gambles+1,env.outcomes))\n",
    "    grid[0,:] = env.dist\n",
    "    for i in range(len(actions[:-1])):\n",
    "        gamble, outcome = action_coordinate(env,actions[i]) \n",
    "        grid[gamble+1, outcome] = i+1\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMPS Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [0, 4, 8, 12, 16, 20, 24, 1, 25, 3, 27, 17, 9, 26, 28],\n",
       " 'ground_truth': array([  6.47 ,   6.087,  -1.174,   5.377,   3.701,   1.684,   2.161,  11.175,   4.598,   0.618,   6.018,   2.667,   2.956,  10.258,   6.065,   6.735,   4.684,   3.304,   6.411,   1.559,   4.026,\n",
       "         -1.827,  12.119,   5.962,   9.065,   3.787,   9.321,   5.913]),\n",
       " 'observations': 14,\n",
       " 'util': 6.2582775286568371}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs[21].reset()\n",
    "trace = run_env(bo_pol, train_envs[21])\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36,  0.35,  0.11,  0.18])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs[21].dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.4697168852787925, 6.0874747782387573, Norm(5.00, 2.99), 5.3770647738841024],\n",
       "       [3.7011480847344491, Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [4.5980424669356585, 0.61757752425761225, Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [2.9558591442380684, Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [4.6841451447763056, 3.3036118244326227, Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [4.0261650303765464, Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [9.0650927676074815, 3.7866146709433091, 9.3205178230600225, 5.9126224275076842]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs[21].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.36,   0.35,   0.11,   0.18],\n",
       "       [  1.  ,   8.  ,   0.  ,  10.  ],\n",
       "       [  2.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [  3.  ,  13.  ,   0.  ,   0.  ],\n",
       "       [  4.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [  5.  ,  12.  ,   0.  ,   0.  ],\n",
       "       [  6.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [  7.  ,   9.  ,  14.  ,  11.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_grid(train_envs[21],trace['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [16, 12, 20, 4, 8, 0, 1, 3, 2, 24, 25, 27, 26, 28],\n",
       " 'ground_truth': array([  6.47 ,   6.087,  -1.174,   5.377,   3.701,   1.684,   2.161,  11.175,   4.598,   0.618,   6.018,   2.667,   2.956,  10.258,   6.065,   6.735,   4.684,   3.304,   6.411,   1.559,   4.026,\n",
       "         -1.827,  12.119,   5.962,   9.065,   3.787,   9.321,   5.913]),\n",
       " 'observations': 13,\n",
       " 'options': [(4, 1),\n",
       "  (3, 1),\n",
       "  (5, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (0, 1),\n",
       "  (0, 1),\n",
       "  (0, 1),\n",
       "  (0, 1),\n",
       "  (6, 1),\n",
       "  (6, 1),\n",
       "  (6, 1),\n",
       "  (6, 1),\n",
       "  (-99, 1)],\n",
       " 'util': 6.2882775286568364}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs[21].reset()\n",
    "trace = run_dc(train_envs[21])\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36,  0.35,  0.11,  0.18])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs[21].dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.4697168852787925, 6.0874747782387573, -1.1743937774121251, 5.3770647738841024],\n",
       "       [3.7011480847344491, Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [4.5980424669356585, Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [2.9558591442380684, Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [4.6841451447763056, Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [4.0261650303765464, Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99)],\n",
       "       [9.0650927676074815, 3.7866146709433091, 9.3205178230600225, 5.9126224275076842]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs[21].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.36,   0.35,   0.11,   0.18],\n",
       "       [  6.  ,   7.  ,   9.  ,   8.  ],\n",
       "       [  4.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [  5.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [  2.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [  1.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [  3.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [ 10.  ,  11.  ,  13.  ,  12.  ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_grid(train_envs[21],trace['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_env(gambles=4, cost=.01, ground_truth=False, dist=hd_dist(3), stakes = 'high'):\n",
    "    reward = Normal((9.99+0.01)/2, 0.3*(9.99-0.01)) if stakes == 'high' else Normal((0.25+0.01)/2, 0.3*(0.25-0.01))\n",
    "    return OldMouselabEnv(gambles, dist, reward, cost, ground_truth= ground_truth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = train_envs[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env2 = make_env(ground_truth=env.ground_truth,dist=env.dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.47 ,   6.087,  -1.174,   5.377,   3.701,   1.684,   2.161,  11.175,   4.598,   0.618,   6.018,   2.667,   2.956,  10.258,   6.065,   6.735,   4.684,   3.304,   6.411,   1.559,   4.026,\n",
       "        -1.827,  12.119,   5.962,   9.065,   3.787,   9.321,   5.913])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.47 ,   6.087,  -1.174,   5.377,   3.701,   1.684,   2.161,  11.175,   4.598,   0.618,   6.018,   2.667,   2.956,  10.258,   6.065,   6.735,   4.684,   3.304,   6.411,   1.559,   4.026,\n",
       "        -1.827,  12.119,   5.962,   9.065,   3.787,   9.321,   5.913])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2.ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [0, 4, 8, 12, 16, 20, 24, 1, 25, 3, 27, 17, 9, 26, 28],\n",
       " 'ground_truth': array([  6.47 ,   6.087,  -1.174,   5.377,   3.701,   1.684,   2.161,  11.175,   4.598,   0.618,   6.018,   2.667,   2.956,  10.258,   6.065,   6.735,   4.684,   3.304,   6.411,   1.559,   4.026,\n",
       "         -1.827,  12.119,   5.962,   9.065,   3.787,   9.321,   5.913]),\n",
       " 'observations': 14,\n",
       " 'util': 6.2582775286568371}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = run_env(bo_pol, env)\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [0, 4, 8, 12, 16, 20, 24, 1, 25, 3, 27, 17, 9, 26, 28],\n",
       " 'ground_truth': array([  6.47 ,   6.087,  -1.174,   5.377,   3.701,   1.684,   2.161,  11.175,   4.598,   0.618,   6.018,   2.667,   2.956,  10.258,   6.065,   6.735,   4.684,   3.304,   6.411,   1.559,   4.026,\n",
       "         -1.827,  12.119,   5.962,   9.065,   3.787,   9.321,   5.913]),\n",
       " 'observations': 14,\n",
       " 'util': 6.5382775286568373}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = run_env(bo_pol, env2)\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrap_po(env,click_sequence,t=1,p_rand=0):\n",
    "    memo = dict()\n",
    "    def parse_options_clean(init_state,dist,stakes,pre_acts,click_sequence,t=1,p_err=0.001):\n",
    "        if click_sequence == []: \n",
    "            return True, [[]], [1]\n",
    "        \n",
    "        if (tuple(pre_acts),tuple(click_sequence),tuple(dist),t,p_err,stakes) in memo:       \n",
    "            return memo[(tuple(pre_acts),tuple(click_sequence),tuple(dist),t,p_err,stakes)]   \n",
    "        \n",
    "        envc = make_env(ground_truth=init_state, dist=dist, stakes=stakes)\n",
    "        envc.reset()\n",
    "        for a in pre_acts:\n",
    "            envc._step(a)\n",
    "\n",
    "        option_seqs = []\n",
    "        likelihoods = []\n",
    "        done = False\n",
    "        options, option_insts, option_utils, n_available_clicks,_,_,_ = get_all_options(envc)\n",
    "        \n",
    "        for i,j in product(range(1,min(len(dist),len(click_sequence))+1),range(len(options))):\n",
    "            option = options[j]\n",
    "            n_insts = len(option_insts[option])\n",
    "            for inst in option_insts[option]:\n",
    "                if np.array_equal(click_sequence[:i],inst): \n",
    "                    will_done, remaining, rem_likelihoods = (parse_options_clean(init_state,dist,stakes,pre_acts+click_sequence[:i],click_sequence[i:],t,p_rand))\n",
    "                    done = done or will_done  \n",
    "                    if done:\n",
    "                        for k in range(len(remaining)): \n",
    "                            option_seqs.append([option]+remaining[k]) \n",
    "#                             l_opt_seq = ((1-p_rand)*np.exp(1/t*option_utils[j])/np.sum(np.exp(1/t*option_utils))\n",
    "#                                         + p_rand*np.prod([1/(n_available_clicks-k) for k in range(option[1])]))\n",
    "                            alpha = 1 if option == (-1,1) else 0 \n",
    "                            l_opt_seq = ((1-p_rand)*np.exp(1/t*option_utils[j])/np.sum(np.exp(1/t*option_utils))\n",
    "                                    + p_rand*alpha)\n",
    "                            likelihoods.append(l_opt_seq*rem_likelihoods[k]/n_insts)               \n",
    "        memo[(tuple(pre_acts),tuple(click_sequence),tuple(dist),t,p_err,stakes)] = done, option_seqs, likelihoods\n",
    "        return done, option_seqs, likelihoods\n",
    "    stakes = 'high' if env.reward.mu == 5.0 else 'low'\n",
    "    if click_sequence[-1] != env.term_action:\n",
    "        click_sequence = click_sequence+[env.term_action]\n",
    "    return parse_options_clean(env.ground_truth,env.dist,stakes,[],click_sequence,t,p_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [9, 0, 3, 6, 7, 10, 8, 4, 5, 12],\n",
       " 'ground_truth': array([ 1.761,  3.758,  5.988,  2.494,  9.29 ,  8.147,  5.778,  1.885,  9.136,  4.096,  0.055,  4.033]),\n",
       " 'observations': 9,\n",
       " 'options': [(3, 1),\n",
       "  (0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (2, 1),\n",
       "  (1, 2),\n",
       "  (-99, 1)],\n",
       " 'util': 6.049648835573457}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env = train_envs[21]\n",
    "env = OldMouselabEnv(4, ld_dist(3), reward, cost)\n",
    "env.reset()\n",
    "trace = run_dc(env)\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = wrap_po(env,trace['actions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(3, 1),\n",
       "   (0, 1),\n",
       "   (1, 1),\n",
       "   (2, 1),\n",
       "   (2, 1),\n",
       "   (3, 1),\n",
       "   (2, 1),\n",
       "   (1, 1),\n",
       "   (1, 1),\n",
       "   (-99, 1)],\n",
       "  5.4927478469475942e-09),\n",
       " ([(3, 1), (0, 1), (1, 1), (2, 1), (2, 1), (3, 1), (2, 1), (1, 2), (-99, 1)],\n",
       "  2.1687414744955522e-08),\n",
       " ([(3, 1), (0, 1), (1, 1), (2, 2), (3, 1), (2, 1), (1, 1), (1, 1), (-99, 1)],\n",
       "  3.2320519222132416e-08),\n",
       " ([(3, 1), (0, 1), (1, 1), (2, 2), (3, 1), (2, 1), (1, 2), (-99, 1)],\n",
       "  1.2761345043942281e-07)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(list(np.array(b)[np.array(c)!=0]),np.array(c)[np.array(c)!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
