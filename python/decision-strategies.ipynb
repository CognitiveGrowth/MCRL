{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import random\n",
    "import itertools as it\n",
    "from joblib import Parallel, delayed\n",
    "from toolz import memoize\n",
    "from contracts import contract\n",
    "from collections import namedtuple, defaultdict, deque, Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "                        message=\"The objective has been evaluated at this point before.\")\n",
    "\n",
    "from agents import Agent\n",
    "from oldmouselab import OldMouselabEnv\n",
    "from policies import FixedPlanPolicy, LiederPolicy\n",
    "from evaluation import *\n",
    "from distributions import cmax, smax, sample, expectation, Normal, PointMass, SampleDist, Normal, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hd_dist(attributes):\n",
    "    dist = [1,]*attributes\n",
    "    dist[0] = np.random.randint(85,97)\n",
    "    for i in range(1,attributes-1):\n",
    "        dist[i] += np.random.randint(0,100-np.sum(dist))\n",
    "    dist[-1] += 100-np.sum(dist)\n",
    "    dist = np.around(np.array(dist)/100,decimals=2)\n",
    "    np.random.shuffle(dist)\n",
    "    return dist\n",
    "\n",
    "def ld_dist(attributes):\n",
    "    dist = [np.random.randint(10,40) for _ in range(attributes)]\n",
    "    dist = np.around(np.array(dist)/sum(dist),decimals=2)\n",
    "    np.random.shuffle(dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gambles = 7\n",
    "attributes = 4\n",
    "high_stakes = Normal((9.99+0.01)/2, 0.3*(9.99-0.01))\n",
    "low_stakes = Normal((0.25+0.01)/2, 0.3*(0.25-0.01))\n",
    "reward = high_stakes\n",
    "cost=.03\n",
    "\n",
    "n_test = 100\n",
    "\n",
    "test_envs_hd =  [OldMouselabEnv(gambles, hd_dist(attributes), reward, cost) for _ in range(n_test)]\n",
    "test_envs_ld = [OldMouselabEnv(gambles, ld_dist(attributes), reward, cost) for _ in range(n_test)]\n",
    "test_envs_all = test_envs_hd+test_envs_ld \n",
    "\n",
    "term_action = train_envs[0].term_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "def run_env(policy, env):\n",
    "    agent.register(env)\n",
    "    agent.register(policy)\n",
    "    tr = agent.run_episode()\n",
    "#     print(tr)\n",
    "    return {'util': tr['return'], 'actions': tr['actions'],\n",
    "            'observations': len(tr['actions']) - 1, 'ground_truth': env.ground_truth}\n",
    "\n",
    "def characterize_strategy(policy,envs):\n",
    "    operations = np.array([])\n",
    "    nr_clicks = np.array([])\n",
    "    probabilities = np.array([])\n",
    "    returns =np.array([])\n",
    "    observations =np.array([])\n",
    "    \n",
    "    for i in range(len(test_envs)):\n",
    "        train_envs[i].reset()\n",
    "        trace = run_env(bo_pol, test_envs[i])\n",
    "        returns = np.append(returns,trace['util'])\n",
    "        observations = np.append(observations,trace['observations'])\n",
    "        operations = np.append(operations, trace['actions']) \n",
    "        nr_clicks = np.append(nr_clicks,[len(trace['actions'])-1])\n",
    "        probabilities = np.append(probabilities,test_envs[i].dist) \n",
    "    \n",
    "    return {'returns': returns, 'observations': observations, 'operations':operations, 'nr_clicks': nr_clicks, 'probabilities': probabilities}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High stakes, high dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo_pol_theta = np.load('data/high_stakes_3cents.npy')\n",
    "bo_pol_high_stakes = LiederPolicy(list(bo_pol_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hd_hs = characterize_strategy(bo_pol_high_stakes,test_envs_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the high-dispersion environment the BO policy made between 3.0 and 18.0 clicks. The average number of clicks was 8.9\n"
     ]
    }
   ],
   "source": [
    "avg_nr_clicks_hd_hs=np.mean(hd_hs['nr_clicks'])\n",
    "min_nr_clicks_hd_hs=np.min(hd_hs['nr_clicks'])\n",
    "max_nr_clicks_hd_hs=np.max(hd_hs['nr_clicks'])\n",
    "\n",
    "print('In the high-dispersion environment the BO policy made between {} and {} clicks. The average number of clicks was {:3.2}'.format(min_nr_clicks_hd_hs,max_nr_clicks_hd_hs,avg_nr_clicks_hd_hs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# High stakes, low dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo_pol_theta = np.load('data/high_stakes_3cents.npy')\n",
    "bo_pol_high_stakes = LiederPolicy(list(bo_pol_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ld_hs = characterize_strategy(bo_pol_high_stakes,test_envs_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_nr_clicks_ld_hs=np.mean(hd_hs['nr_clicks'])\n",
    "min_nr_clicks_ld_hs=np.min(hd_hs['nr_clicks'])\n",
    "max_nr_clicks_ld_hs=np.max(hd_hs['nr_clicks'])\n",
    "\n",
    "print('In the low-dispersion environment the BO policy made between {} and {} clicks. The average number of clicks was {:4.2}'.format(min_nr_clicks_ld_hs,max_nr_clicks_ld_hs,avg_nr_clicks_ld_hs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low stakes, high dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo_pol_theta = np.load('data/low_stakes_3cents.npy')\n",
    "bo_pol_low_stakes = LiederPolicy(list(bo_pol_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hd_ls = characterize_strategy(bo_pol_low_stakes,test_envs_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_nr_clicks_hd_ls=np.mean(hd_ls['nr_clicks'])\n",
    "min_nr_clicks_hd_ls=np.min(hd_ls['nr_clicks'])\n",
    "max_nr_clicks_hd_ls=np.max(hd_ls['nr_clicks'])\n",
    "\n",
    "print('In the high-dispersion environment the low-stakes policy made between {} and {} clicks. The average number of clicks was {:4.2}'.format(min_nr_clicks_hd_ls,max_nr_clicks_hd_ls,avg_nr_clicks_hd_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low stakes, low dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bo_pol_theta = np.load('data/low_stakes_3cents.npy')\n",
    "bo_pol_low_stakes = LiederPolicy(list(bo_pol_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ld_ls = characterize_strategy(bo_pol_low_stakes,test_envs_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_nr_clicks_ld_ls=np.mean(ld_ls['nr_clicks'])\n",
    "min_nr_clicks_ld_ls=np.min(ld_ls['nr_clicks'])\n",
    "max_nr_clicks_ld_ls=np.max(ld_ls['nr_clicks'])\n",
    "\n",
    "print('In the low-dispersion environment the low-stakes policy made between {} and {} clicks. The average number of clicks was {:4.2}'.format(min_nr_clicks_ld_ls,max_nr_clicks_ld_ls,avg_nr_clicks_ld_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
