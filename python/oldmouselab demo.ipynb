{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import random\n",
    "import itertools as it\n",
    "from joblib import Parallel, delayed\n",
    "from toolz import memoize\n",
    "from contracts import contract\n",
    "from collections import namedtuple, defaultdict, deque, Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "                        message=\"The objective has been evaluated at this point before.\")\n",
    "\n",
    "from agents import Agent\n",
    "from oldmouselab import OldMouselabEnv\n",
    "from policies import FixedPlanPolicy, LiederPolicy\n",
    "from evaluation import *\n",
    "from distributions import cmax, smax, sample, expectation, Normal, PointMass, SampleDist, Normal, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hd_dist(attributes):\n",
    "    dist = [1,]*attributes\n",
    "    dist[0] = np.random.randint(85,97)\n",
    "    for i in range(1,attributes-1):\n",
    "        dist[i] += np.random.randint(0,100-np.sum(dist))\n",
    "    dist[-1] += 100-np.sum(dist)\n",
    "    dist = np.around(np.array(dist)/100,decimals=2)\n",
    "    np.random.shuffle(dist)\n",
    "    return dist\n",
    "\n",
    "def ld_dist(attributes):\n",
    "    dist = [np.random.randint(10,40) for _ in range(attributes)]\n",
    "    dist = np.around(np.array(dist)/sum(dist),decimals=2)\n",
    "    np.random.shuffle(dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gambles = 7\n",
    "attributes = 4\n",
    "high_stakes = Normal((9.99+0.01)/2, 0.3*(9.99-0.01))\n",
    "low_stakes = Normal((0.25+0.01)/2, 0.3*(0.25-0.01))\n",
    "reward = high_stakes\n",
    "cost=.03\n",
    "\n",
    "#set to 20 for sanity check\n",
    "n_train = 20\n",
    "n_test = 20\n",
    "\n",
    "train_envs_hd = [OldMouselabEnv(gambles, hd_dist(attributes), reward, cost) for _ in range(n_train)]\n",
    "train_envs_ld = [OldMouselabEnv(gambles, ld_dist(attributes), reward, cost) for _ in range(n_train)]\n",
    "train_envs = train_envs_hd+train_envs_ld \n",
    "\n",
    "test_envs_hd =  [OldMouselabEnv(gambles, hd_dist(attributes), reward, cost) for _ in range(n_train)]\n",
    "test_envs_ld = [OldMouselabEnv(gambles, ld_dist(attributes), reward, cost) for _ in range(n_train)]\n",
    "test_envs = test_envs_hd+test_envs_ld \n",
    "\n",
    "term_action = train_envs[0].term_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo_pol_theta = np.load('data/high_stakes_3cents.npy')\n",
    "bo_pol = LiederPolicy(list(bo_pol_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "def run_env(policy, env):\n",
    "    agent.register(env)\n",
    "    agent.register(policy)\n",
    "    tr = agent.run_episode()\n",
    "#     print(tr)\n",
    "    return {'util': tr['return'], 'actions': tr['actions'],\n",
    "            'observations': len(tr['actions']) - 1, 'ground_truth': env.ground_truth}\n",
    "\n",
    "def action_coordinate(env, action):\n",
    "    return (action//env.outcomes,action%env.outcomes)\n",
    "\n",
    "def p_grid(env, actions):\n",
    "    grid = np.zeros((env.gambles+1,env.outcomes))\n",
    "    grid[0,:] = env.dist\n",
    "    for i in range(len(actions[:-1])):\n",
    "        gamble, outcome = action_coordinate(env,actions[i]) \n",
    "        grid[gamble+1, outcome] = i+1\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [15, 11, 3, 7, 23, 19, 18, 14, 27, 16, 12, 6, 4, 20, 2, 28],\n",
       " 'ground_truth': array([  5.72 ,   3.217,   2.329,   4.651,   6.133,   5.194,   9.519,   5.233,   6.989,  -2.191,  10.047,   2.322,   1.857,  10.419,   2.03 ,   8.164,   3.851,   5.734,   6.694,   6.005,   2.839,\n",
       "         10.503,   3.574,   4.335,   5.184,  10.58 ,   7.042,   5.057]),\n",
       " 'observations': 15,\n",
       " 'util': 6.0173855517845771}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs[21].reset()\n",
    "trace = run_env(bo_pol, train_envs[21])\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23,  0.19,  0.25,  0.33])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs[21].dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[Norm(5.00, 2.99), Norm(5.00, 2.99), 2.3291105682994981, 4.6506266465148158],\n",
       "       [6.1326595288813932, Norm(5.00, 2.99), 9.5193876241208599, 5.2334150124595205],\n",
       "       [Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99), 2.3220610718772274],\n",
       "       [1.8569011494096928, Norm(5.00, 2.99), 2.0300837314080731, 8.1643066308078609],\n",
       "       [3.8510808099828533, Norm(5.00, 2.99), 6.6942617780405316, 6.0054604865583121],\n",
       "       [2.8387405059890871, Norm(5.00, 2.99), Norm(5.00, 2.99), 4.335424968102747],\n",
       "       [Norm(5.00, 2.99), Norm(5.00, 2.99), Norm(5.00, 2.99), 5.0567247344048454]], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_envs[21].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.23,   0.19,   0.25,   0.33],\n",
       "       [  0.  ,   0.  ,  15.  ,   3.  ],\n",
       "       [ 13.  ,   0.  ,  12.  ,   4.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   2.  ],\n",
       "       [ 11.  ,   0.  ,   8.  ,   1.  ],\n",
       "       [ 10.  ,   0.  ,   7.  ,   6.  ],\n",
       "       [ 14.  ,   0.  ,   0.  ,   5.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   9.  ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_grid(train_envs[21],trace['actions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
