var L = webpplMouselab;
var round = function(x, p) {Math.round(x * Math.pow(10, p)) / Math.pow(10, p)}

// var vals = function(mu,sigma) {
//   // Temporarily hardcoding the values...
//   // map(function(x) {mu + x * sigma}, [-2, -1, 1, 2])
//   // [-15, -5, 5, 15]
//   [-20.0, -12.0, -4.0, 4.0, 12.0, 20.0]
// };


// var probs = function() {
//   // [0.159,  0.341,  0.341,  0.159]
//   [0.055, 0.157, 0.288, 0.288, 0.157, 0.055]
// };
// globalStore.cost = -1
// globalStore.reward = Categorical({vs: vals(1, 2),
//                                   ps: probs()});

// Run 10 rollouts of the given policy, return average total reward.
var run = function(policy, samples, name) {
  var result = timeit(function() {
    return Infer({model() {
      simulate(policy);
    }, 
    method: 'forward', samples: samples || 10,
      // method: 'enumerate'  // integrate out all possible outcomes (slow!)
    });
  });
  var avgUtil = expectation(Infer({model() {
    sum(sample(result.value).rewards)}
  }));
  var avgNumObs = expectation(Infer({model() {
    sample(result.value).actions.length - 1}
  }));
  console.log(
    (name || 'run'), ':',
    round(avgUtil, 3), ' ',
    round(avgNumObs, 3), ' ',
    result.runtimeInMilliseconds
  )
  return avgUtil
}

// This function doesn't work because vals and probs
// are harcoded above.
var testParams = function(mu, sigma) {
  globalStore.reward = Categorical({vs: vals(mu, sigma),
                                    ps: probs()});
  var policy = enumPolicy();
  run(policy, 1000, 'N('+mu+', '+sigma+')')
};

var evalPolicyWeights = function() {
  // var weights = JSON.parse(argv.weights)
  var weights = [ -0.034821394751660226, 4.177078845688222, 1.216868835535616, 6.726366072163112, -1.1604972774449753 ];
  console.log('weights', weights)
  var Q = makeQ_meta(weights);
  var policy = maxQPolicy(Q);
  run(policy, 100, 'result')
};

// var result = timeit(function() {
//   sample(inferWeights())
// });
// console.log(result)

// var weights = result.value.weights;
// run(maxQPolicy(makeQ_meta(weights)), 10000, 'SMC')
// run(maxQPolicy(makeQ_meta([-4.5318, -0.47478, 30.0, 30.0, -9.20915])), 10000, 'BO')

// var state = L.updateList(env.initialState, 1, 5)
// timeit(function() {
//   // calculatePR({state: env.initialState, action: 1})
//   VPI_full(state)
// })

evalPolicyWeights()

// run(maxQPolicy(makeQ_meta([-4.5318, -0.47478, 30.0, 30.0, -9.20915])), 1)



// // var state = env.initialState;
// console.log([
//   globalStore.cost,
//   VOC_1(state, 2),
//   VPI_action(state, 2),
//   VPI_full(state),
//   termValue(state)
// ])



// var infer = function() {
//   Infer({model() {
//     var arms = _.range(20);
//     var a = uniformDraw(arms);
//     factor(100 * gaussian(a, 10));
//     factor(100 * gaussian(a, 10));
//     factor(1000 * gaussian(a, 10));
//     a
//   }, 
//   // method: 'MCMC', samples: 20
//   method: 'SMC', particles: 20, rejuvSteps: 2
//   })  
// };

// infer()



// console.log(env.initialState)
// console.log(JSON.stringify(obsTree(env.initialState, [])))
// console.log(JSON.stringify())



// console.log([
//   // globalStore.V.cache.length,
//   globalStore.Q.cache.length,
//   // globalStore.policy.cache.length,
// ])
// var env = L.buildCross(2, 2)
// env.hashState(env.initialState)

// testParams(-1, 8, 3)
// testParams(-1, 8, 4)
// testParams(-1, 8, 5)
// testParams(-1, 8, 10000)
// testParams(3, 2)

// testParams(-1, 8)
// testParams(0, 8)
// testParams(1, 8)

// var pol = enumPolicy()
// repeat(100, function() {sum(simulate(pol).rewards)})


// globalStore.reward = Categorical({vs: vals(-1, 8),
//                                   ps: probs()});
// simulate(enumPolicy({
//   lookahead: 2
// }))

// L.firstUnobserved(['a', 'aa', 'b', 'ccc'])


